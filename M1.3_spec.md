# Milestone 1.3 Specification: Database Bootstrap (PostgreSQL) + Migrations

## Overview

**Goal:** Establish persistent storage foundation with PostgreSQL database, migration tooling, and initial schema for core entities.

**Duration:** 2-3 days

**Dependencies:**

- Milestone 1.1 (Repo, CI, and Dev Scaffolding) must be complete
- Milestone 1.2 (FastAPI Skeleton) must be complete

## Objectives

Create a robust database layer with:

- PostgreSQL 15 integration with connection pooling
- Alembic migration framework setup
- Initial schema for core entities (users, topics, sources, articles)
- SQLAlchemy ORM models with type safety
- Database health checks integrated with `/readyz` endpoint
- Development and testing database configurations

## Technical Requirements

### 1. Database Configuration

**PostgreSQL Setup:**

```yaml
# docker-compose.dev.yml addition
services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: morning_brief
      POSTGRES_USER: mb_user
      POSTGRES_PASSWORD: mb_dev_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/db/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mb_user -d morning_brief"]
      interval: 10s
      timeout: 5s
      retries: 5
```

**Connection String:**

- Development: `postgresql://mb_user:mb_dev_password@localhost:5432/morning_brief`
- Test: `postgresql://mb_user:mb_test_password@localhost:5433/morning_brief_test`
- Production: From environment variable `DATABASE_URL`

### 2. Project Structure

**New Files and Directories:**

```
backend/
├── app/
│   ├── db/
│   │   ├── __init__.py
│   │   ├── base.py           # Base model class
│   │   ├── session.py        # Database session management
│   │   └── dependencies.py   # FastAPI dependency injection
│   ├── models/
│   │   ├── __init__.py
│   │   ├── user.py          # User model
│   │   ├── topic.py         # Topic model
│   │   ├── source.py        # Source model
│   │   └── article.py       # Article model
│   └── core/
│       └── config.py         # Updated with DB settings
├── alembic/
│   ├── versions/             # Migration files
│   ├── env.py               # Alembic environment
│   ├── script.py.mako       # Migration template
│   └── README
├── alembic.ini              # Alembic configuration
├── db/
│   └── init.sql             # Initial DB setup script
└── tests/
    └── test_database.py     # Database connection tests
```

### 3. SQLAlchemy Models

#### Base Model Class

```python
# app/db/base.py
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import Column, Integer, DateTime
from datetime import datetime

class BaseModel:
    """Base model with common fields"""
    id = Column(Integer, primary_key=True, index=True)
    created_at = Column(DateTime, default=datetime.utcnow, nullable=False)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False)

Base = declarative_base(cls=BaseModel)
```

#### User Model

```python
# app/models/user.py
from sqlalchemy import Column, String, Boolean
from app.db.base import Base

class User(Base):
    __tablename__ = "users"

    email = Column(String(255), unique=True, nullable=False, index=True)
    is_active = Column(Boolean, default=True, nullable=False)
    # Additional fields for future auth implementation
    # hashed_password will be added in auth milestone
```

#### Topic Model

```python
# app/models/topic.py
from sqlalchemy import Column, String, ForeignKey, JSON
from sqlalchemy.orm import relationship
from app.db.base import Base

class Topic(Base):
    __tablename__ = "topics"

    user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    name = Column(String(255), nullable=False)
    keywords = Column(JSON, default=list, nullable=False)  # List of keyword strings
    is_active = Column(Boolean, default=True, nullable=False)

    # Relationships
    user = relationship("User", back_populates="topics")
    deliveries = relationship("Delivery", back_populates="topic")
```

#### Source Model

```python
# app/models/source.py
from sqlalchemy import Column, String, Float, Boolean, DateTime
from app.db.base import Base

class Source(Base):
    __tablename__ = "sources"

    name = Column(String(255), nullable=False)
    url = Column(String(512), unique=True, nullable=False)
    feed_url = Column(String(512), unique=True, nullable=False)
    credibility_score = Column(Float, default=0.5, nullable=False)  # 0.0 to 1.0
    is_active = Column(Boolean, default=True, nullable=False)
    last_fetched_at = Column(DateTime, nullable=True)
    last_error = Column(String(1024), nullable=True)
    error_count = Column(Integer, default=0, nullable=False)

    # Relationships
    articles = relationship("Article", back_populates="source")
```

#### Article Model

```python
# app/models/article.py
from sqlalchemy import Column, String, Text, ForeignKey, DateTime, Index
from sqlalchemy.orm import relationship
from app.db.base import Base

class Article(Base):
    __tablename__ = "articles"

    source_id = Column(Integer, ForeignKey("sources.id"), nullable=False)
    title = Column(String(512), nullable=False)
    link = Column(String(1024), nullable=False)
    summary_raw = Column(Text, nullable=True)  # Original RSS description
    content_hash = Column(String(64), unique=True, nullable=False)  # SHA256 for dedup
    published_at = Column(DateTime, nullable=False)
    author = Column(String(255), nullable=True)
    tags = Column(JSON, default=list, nullable=False)  # List of tag strings

    # Indexes for performance
    __table_args__ = (
        Index('idx_published_at', 'published_at'),
        Index('idx_source_published', 'source_id', 'published_at'),
        Index('idx_content_hash', 'content_hash'),
    )

    # Relationships
    source = relationship("Source", back_populates="articles")
    summaries = relationship("ArticleSummary", back_populates="article")
    deliveries = relationship("Delivery", back_populates="article")
```

### 4. Additional Models (For Future Use)

```python
# app/models/article_summary.py
class ArticleSummary(Base):
    __tablename__ = "article_summaries"

    article_id = Column(Integer, ForeignKey("articles.id"), nullable=False)
    summary_text = Column(Text, nullable=False)
    model = Column(String(50), nullable=False)  # e.g., "gpt-3.5-turbo"
    tokens_used = Column(Integer, nullable=False)

    # Unique constraint: one summary per article per model
    __table_args__ = (
        UniqueConstraint('article_id', 'model', name='uq_article_model'),
    )

    article = relationship("Article", back_populates="summaries")

# app/models/delivery.py
class Delivery(Base):
    __tablename__ = "deliveries"

    user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    topic_id = Column(Integer, ForeignKey("topics.id"), nullable=False)
    article_id = Column(Integer, ForeignKey("articles.id"), nullable=False)
    delivery_date = Column(Date, nullable=False)
    position = Column(Integer, nullable=False)  # 1, 2, or 3

    # Unique constraint: one article per topic per date per position
    __table_args__ = (
        UniqueConstraint('topic_id', 'delivery_date', 'article_id', name='uq_topic_date_article'),
        UniqueConstraint('topic_id', 'delivery_date', 'position', name='uq_topic_date_position'),
    )

    user = relationship("User", back_populates="deliveries")
    topic = relationship("Topic", back_populates="deliveries")
    article = relationship("Article", back_populates="deliveries")
    feedback = relationship("Feedback", back_populates="delivery", uselist=False)

# app/models/feedback.py
class Feedback(Base):
    __tablename__ = "feedback"

    delivery_id = Column(Integer, ForeignKey("deliveries.id"), unique=True, nullable=False)
    rating = Column(String(10), nullable=False)  # "up" or "down"
    comment = Column(Text, nullable=True)

    delivery = relationship("Delivery", back_populates="feedback")
```

### 5. Database Session Management

```python
# app/db/session.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker, Session
from sqlalchemy.pool import NullPool
from app.core.config import settings

# Create engine with connection pooling
engine = create_engine(
    settings.DATABASE_URL,
    pool_pre_ping=True,  # Verify connections before using
    pool_size=10,        # Number of persistent connections
    max_overflow=20,     # Maximum overflow connections
    echo=settings.DEBUG  # Log SQL statements in debug mode
)

# Create session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def get_db() -> Generator[Session, None, None]:
    """
    Dependency to get database session.
    Ensures proper cleanup after request.
    """
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
```

### 6. Alembic Migration Setup

#### Configuration

```ini
# alembic.ini
[alembic]
script_location = alembic
prepend_sys_path = .
version_path_separator = os
sqlalchemy.url = postgresql://mb_user:mb_dev_password@localhost:5432/morning_brief

[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S
```

#### Environment Configuration

```python
# alembic/env.py
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import os
import sys
from pathlib import Path

# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))

from app.db.base import Base
from app.models import *  # Import all models
from app.core.config import settings

config = context.config

# Override sqlalchemy.url with environment variable if present
if settings.DATABASE_URL:
    config.set_main_option("sqlalchemy.url", settings.DATABASE_URL)

fileConfig(config.config_file_name)
target_metadata = Base.metadata

def run_migrations_offline():
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
    )

    with context.begin_transaction():
        context.run_migrations()

def run_migrations_online():
    """Run migrations in 'online' mode."""
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata
        )

        with context.begin_transaction():
            context.run_migrations()

if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()
```

### 7. Initial Migration

```bash
# Commands to create initial migration
alembic init alembic
alembic revision --autogenerate -m "Initial schema with users, topics, sources, articles"
alembic upgrade head
```

### 8. Database Health Check Integration

```python
# app/api/health.py (updated)
from fastapi import APIRouter, Depends, status
from sqlalchemy.orm import Session
from sqlalchemy import text
from app.db.session import get_db
from app.core.config import settings

router = APIRouter()

@router.get("/readyz")
async def readiness_check(db: Session = Depends(get_db)):
    """
    Check if the application is ready to serve traffic.
    Includes database connectivity check.
    """
    try:
        # Check database connection
        db.execute(text("SELECT 1"))
        db.commit()

        return {
            "status": "ready",
            "database": "connected",
            "version": settings.VERSION
        }
    except Exception as e:
        return JSONResponse(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            content={
                "status": "not_ready",
                "database": "disconnected",
                "error": str(e) if settings.DEBUG else "Database connection failed"
            }
        )
```

### 9. Configuration Updates

```python
# app/core/config.py (updated)
from pydantic import BaseSettings, PostgresDsn, validator
from typing import Optional

class Settings(BaseSettings):
    # Existing settings...

    # Database settings
    DATABASE_URL: Optional[PostgresDsn] = None
    DATABASE_POOL_SIZE: int = 10
    DATABASE_MAX_OVERFLOW: int = 20
    DATABASE_POOL_TIMEOUT: int = 30
    DATABASE_ECHO: bool = False

    # Test database
    TEST_DATABASE_URL: Optional[PostgresDsn] = None

    @validator("DATABASE_URL", pre=True)
    def assemble_db_connection(cls, v: Optional[str], values: dict) -> str:
        if isinstance(v, str):
            return v
        # Build from components if not provided
        return PostgresDsn.build(
            scheme="postgresql",
            user=values.get("POSTGRES_USER", "mb_user"),
            password=values.get("POSTGRES_PASSWORD", "mb_dev_password"),
            host=values.get("POSTGRES_HOST", "localhost"),
            port=values.get("POSTGRES_PORT", "5432"),
            path=f"/{values.get('POSTGRES_DB', 'morning_brief')}"
        )

    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()
```

### 10. Testing Requirements

#### Unit Tests

```python
# tests/test_database.py
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.db.base import Base
from app.core.config import settings

@pytest.fixture(scope="session")
def db_engine():
    """Create test database engine"""
    engine = create_engine(settings.TEST_DATABASE_URL or settings.DATABASE_URL)
    Base.metadata.create_all(bind=engine)
    yield engine
    Base.metadata.drop_all(bind=engine)

@pytest.fixture(scope="function")
def db_session(db_engine):
    """Create a fresh database session for each test"""
    connection = db_engine.connect()
    transaction = connection.begin()
    SessionLocal = sessionmaker(bind=connection)
    session = SessionLocal()

    yield session

    session.close()
    transaction.rollback()
    connection.close()

def test_database_connection(db_session):
    """Test basic database connectivity"""
    result = db_session.execute("SELECT 1")
    assert result.scalar() == 1

def test_user_creation(db_session):
    """Test creating a user"""
    from app.models.user import User

    user = User(email="test@example.com", is_active=True)
    db_session.add(user)
    db_session.commit()

    assert user.id is not None
    assert user.created_at is not None
    assert user.updated_at is not None

def test_topic_with_keywords(db_session):
    """Test creating a topic with keywords"""
    from app.models.user import User
    from app.models.topic import Topic

    user = User(email="test@example.com")
    db_session.add(user)
    db_session.commit()

    topic = Topic(
        user_id=user.id,
        name="Technology",
        keywords=["AI", "machine learning", "robotics"]
    )
    db_session.add(topic)
    db_session.commit()

    assert topic.id is not None
    assert len(topic.keywords) == 3
    assert "AI" in topic.keywords

def test_article_deduplication(db_session):
    """Test article content hash uniqueness"""
    from app.models.source import Source
    from app.models.article import Article
    from datetime import datetime
    import hashlib

    source = Source(
        name="TechCrunch",
        url="https://techcrunch.com",
        feed_url="https://techcrunch.com/feed"
    )
    db_session.add(source)
    db_session.commit()

    content_hash = hashlib.sha256(b"unique_content").hexdigest()

    article1 = Article(
        source_id=source.id,
        title="Test Article",
        link="https://example.com/1",
        content_hash=content_hash,
        published_at=datetime.utcnow()
    )
    db_session.add(article1)
    db_session.commit()

    # Try to add duplicate
    article2 = Article(
        source_id=source.id,
        title="Duplicate Article",
        link="https://example.com/2",
        content_hash=content_hash,  # Same hash
        published_at=datetime.utcnow()
    )
    db_session.add(article2)

    with pytest.raises(IntegrityError):
        db_session.commit()
```

#### Migration Tests

```python
# tests/test_migrations.py
def test_alembic_migrations():
    """Test that all migrations can be applied and rolled back"""
    from alembic.config import Config
    from alembic import command

    alembic_cfg = Config("alembic.ini")

    # Test upgrade
    command.upgrade(alembic_cfg, "head")

    # Test downgrade
    command.downgrade(alembic_cfg, "base")

    # Test upgrade again
    command.upgrade(alembic_cfg, "head")
```

### 11. Makefile Targets

```makefile
# Add to existing Makefile
.PHONY: db-upgrade db-downgrade db-reset db-create-migration

db-upgrade:
	@echo "Upgrading database to latest migration..."
	cd backend && alembic upgrade head

db-downgrade:
	@echo "Downgrading database by one migration..."
	cd backend && alembic downgrade -1

db-reset:
	@echo "Resetting database..."
	cd backend && alembic downgrade base && alembic upgrade head

db-create-migration:
	@echo "Creating new migration..."
	@read -p "Enter migration message: " msg; \
	cd backend && alembic revision --autogenerate -m "$$msg"

db-history:
	@echo "Migration history:"
	cd backend && alembic history --verbose
```

### 12. Docker Compose Updates

```yaml
# docker-compose.dev.yml (updated)
version: "3.8"

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: morning_brief
      POSTGRES_USER: mb_user
      POSTGRES_PASSWORD: mb_dev_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/db/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U mb_user -d morning_brief"]
      interval: 10s
      timeout: 5s
      retries: 5

  postgres-test:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: morning_brief_test
      POSTGRES_USER: mb_user
      POSTGRES_PASSWORD: mb_test_password
    ports:
      - "5433:5432"
    volumes:
      - postgres_test_data:/var/lib/postgresql/data

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      DATABASE_URL: postgresql://mb_user:mb_dev_password@postgres:5432/morning_brief
      LOG_LEVEL: DEBUG
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

volumes:
  postgres_data:
  postgres_test_data:
```

## Quality Gates

### Code Quality

- All models have proper type hints
- SQLAlchemy relationships properly defined
- Alembic migrations are reversible
- No raw SQL unless necessary (use ORM)
- Database queries are optimized with proper indexes

### Performance Requirements

- Connection pool properly configured
- Database queries use appropriate indexes
- Bulk operations use batch inserts where applicable
- N+1 query problems avoided through eager loading

### Security Requirements

- Database credentials never hardcoded
- SQL injection prevention through parameterized queries
- Proper access control on database operations
- Connection string sanitized in logs

## Acceptance Criteria

### Functional Requirements

1. **Migration System:**
   - `alembic upgrade head` successfully creates all tables
   - `alembic downgrade base` successfully removes all tables
   - Migration history is trackable

2. **Database Connection:**
   - Backend connects to PostgreSQL on startup
   - Connection pool manages connections efficiently
   - `/readyz` endpoint reflects database status

3. **Schema Validation:**
   - All tables created with proper constraints
   - Foreign keys properly enforced
   - Unique constraints prevent duplicates
   - Indexes created for performance-critical queries

### Non-Functional Requirements

1. **Development Experience:**
   - `make db-upgrade` applies migrations easily
   - Test database isolated from development
   - Clear error messages for connection failures

2. **Testing:**
   - All models have basic CRUD tests
   - Migration rollback tested
   - Database constraints tested

3. **Documentation:**
   - README updated with database setup instructions
   - Model relationships documented
   - Migration procedures documented

## Deliverables

1. **Database Schema:**
   - Initial migration creating all core tables
   - Proper indexes and constraints
   - Seed data script for development

2. **ORM Models:**
   - SQLAlchemy models for all entities
   - Type-safe relationships
   - Base model with common fields

3. **Migration Framework:**
   - Alembic configured and working
   - Initial migration generated
   - Rollback tested

4. **Integration:**
   - Database health check in `/readyz`
   - Connection pooling configured
   - Docker Compose with PostgreSQL service

5. **Tests:**
   - Model CRUD operations
   - Constraint validation
   - Migration up/down

## Success Metrics

- ✅ `alembic upgrade head` succeeds without errors
- ✅ All tables visible in database after migration
- ✅ `alembic downgrade base` successfully rolls back
- ✅ `/readyz` shows database as "connected"
- ✅ All database tests pass
- ✅ No N+1 query problems in test scenarios
- ✅ Connection pool handles concurrent requests

## Next Steps

Upon completion of Milestone 1.3, the database foundation will be ready for:

- **Milestone 1.4:** RSS Source Seeding and Single-Feed Ingestion
- **Milestone 1.5:** Article normalization and deduplication logic
- **Milestone 2.1:** Topic CRUD operations using the models

The database schema and models established here will serve as the foundation for all data persistence throughout the application.
