# Milestone 1.8 Specification: Summarization Service (OpenAI)

## Overview

**Goal:** Implement a service to generate 2–3 sentence summaries for candidate articles, with retry logic, token/cost guardrails, and persistence in `article_summaries`.

**Duration:** 2–3 days

**Dependencies:**

- Milestone 1.5 (Normalization & Dedup)
- Milestone 1.7 (Baseline Relevance) for candidate selection context

## Objectives

- Add a summarization module using OpenAI API
- Enforce token and rate limits; implement retries with backoff
- Persist summaries to `article_summaries` with model name and tokens used
- Provide CLI to summarize a batch of recent top candidates

## Technical Requirements

### 1. Dependencies and Secrets

- Add `openai` Python SDK or HTTP client of choice
- Add `cryptography` for API key encryption at rest
- Add `slowapi` for rate limiting
- Secrets via encrypted environment variables, not in repo: `OPENAI_API_KEY_ENCRYPTED`

```txt
# backend/requirements.txt additions
openai>=1.51.0
cryptography==41.0.7  # For API key encryption
slowapi==0.1.9  # Rate limiting for API endpoints
```

### 2. Project Structure

```
backend/
├── app/
│   ├── summarization/
│   │   ├── __init__.py
│   │   ├── client.py          # OpenAI client wrapper
│   │   ├── prompts.py         # Prompt templates
│   │   └── summarize_batch.py # CLI/runner for batch summarization
│   ├── ranking/
│   │   └── ranker.py          # Used to select candidates to summarize
│   └── core/
│       └── config.py          # Model, limits, cost guardrails
└── tests/
    └── test_summarization.py
```

### 3. Data Flow

1. Select candidate articles (e.g., top 5–10 per topic in last 24–72 hours) using ranker
2. For each article lacking a summary for the configured model, call summarization
3. Persist summary to `article_summaries` with `(article_id, model)` uniqueness; record `prompt_hash` and optional `input_hash` for provenance

### 4. Prompting and Output

Use a concise prompt instructing a brief, objective 2–3 sentence summary. Include title and sanitized text (title + truncated summary_raw). Example template:

```
You are a helpful assistant. Summarize the following news item in EXACTLY 2-3 concise, objective sentences, avoiding marketing language. Include key facts, entities, and any numbers.

Title: "{title}"
Text: "{text}"
```

Truncate input by tokens (not chars) using the model tokenizer to respect limits.

**Response Validation:**

- Validate that the response contains 2-3 sentences using sentence boundary detection
- If response violates constraints:
  1. First retry: Add stronger constraints to prompt (e.g., "IMPORTANT: Your response MUST be exactly 2-3 sentences. No more, no less.")
  2. Second retry: If still invalid, deterministically truncate/split at sentence boundaries:
     - If 1 sentence: Request expansion with specific prompt
     - If 4+ sentences: Keep first 3 sentences
     - Log validation failures for monitoring
- Store validation status in metadata for quality tracking

### 5. Limits and Guardrails

- `SUMMARY_MAX_TOKENS` (e.g., 120)
- `INPUT_TRUNCATE_TOKENS` (e.g., 800) enforced via tokenizer
- `DAILY_TOKEN_BUDGET` (e.g., 50k tokens) with soft-stop
- `RATE_LIMIT_RPS` (e.g., 2 requests/sec) with sleep
- `GLOBAL_MAX_CONCURRENCY` (e.g., 2) to bound concurrent requests

**Security Guardrails:**

- `DAILY_REQUEST_LIMIT` (e.g., 1000) to prevent abuse
- `DAILY_COST_LIMIT_USD` (e.g., $10) to prevent cost overruns
- `API_KEY_ROTATION_INTERVAL_HOURS` (default 168 = weekly)
- `MAX_RETRY_ATTEMPTS` (default 3) for failed requests
- `REQUEST_TIMEOUT_SEC` (default 30) to prevent hanging requests

### 6. Retry and Error Handling

- Retry on retryable errors (429 rate-limit, 5xx server errors, timeouts) up to 3 attempts with jittered exponential backoff; log request-id if available
- On non-retryable errors (4xx like 400/401/403), log and skip; do not block entire batch
- **Security Error Handling:**
  - Never log API keys in error messages
  - Mask sensitive data in all log outputs
  - Implement circuit breaker pattern for API failures
  - Track and alert on unusual error patterns

### 7. Model Selection

- Configurable model name (e.g., `gpt-4o-mini` or similar) via `SUMMARIZATION_MODEL`
- Store `model`, `prompt_hash`, and `tokens_used` in `article_summaries`

### 8. CLI

Summarize recent top candidates per topic:

```bash
conda run -n ymb-py311 python -m app.summarization.summarize_batch --topic-id 1 --limit 5
conda run -n ymb-py311 python -m app.summarization.summarize_batch --all-topics --limit 3
```

Options:

- `--topic-id` or `--all-topics`
- `--limit` per topic
- `--dry-run` to log which items would be summarized
- `--max-concurrency` to override `GLOBAL_MAX_CONCURRENCY`

### 9. Configuration

Extend `core/config.py`:

**Basic Settings:**

- `SUMMARIZATION_MODEL` (default: `gpt-4o-mini`)
- `SUMMARY_MAX_TOKENS` (120)
- `INPUT_TRUNCATE_TOKENS` (800)
- `DAILY_TOKEN_BUDGET` (50000)
- `RATE_LIMIT_RPS` (2)
- `GLOBAL_MAX_CONCURRENCY` (2)

**Security Settings:**

- `OPENAI_API_KEY_ENCRYPTED` (env) - Encrypted API key
- `API_KEY_ENCRYPTION_KEY_PATH` (env) - Path to encryption key file
- `DAILY_REQUEST_LIMIT` (1000)
- `DAILY_COST_LIMIT_USD` (10.0)
- `API_KEY_ROTATION_INTERVAL_HOURS` (168)
- `REQUEST_TIMEOUT_SEC` (30)
- `ENABLE_COST_TRACKING` (True)
- `MASK_API_KEYS_IN_LOGS` (True)

### 10. Logging and Metrics

- Log per-request: `article_id`, `model`, `prompt_tokens`, `completion_tokens`, `duration_ms`, `validation_status`
- Per-run summary: `summarized`, `skipped_existing`, `errors`, `tokens_total`, `estimated_cost`, `validation_failures`
- Track response quality metrics: sentence count distribution, retry counts

## Testing Requirements

### Unit Tests

- Prompt builder truncates input appropriately using tokenizer counts
- Token accounting and budget soft-stop logic
- Retry on rate-limit exceptions
- **Security Tests:**
  - API key encryption/decryption works correctly
  - Cost and request limits are enforced
  - Sensitive data is masked in logs
  - Rate limiting prevents abuse
  - API key rotation mechanism functions

### Integration Tests

- Mock OpenAI client; simulate success, rate-limit, and failure scenarios (retryable vs non-retryable)
- Ensure `(article_id, model)` uniqueness respected and idempotency holds when inputs unchanged
- Verify different `model` or different `prompt_hash` is treated per current policy (MVP: still unique on model; prompt changes logged)
- **Security Integration Tests:**
  - Test with expired/invalid API keys
  - Verify cost limits prevent overrun
  - Test circuit breaker behavior
  - Validate secure logging of API interactions

## Quality Gates

### Code Quality

- `ruff`/`black`/`mypy` pass

### Safety & Security

- **API Key Security:**
  - No secrets committed to repository
  - API keys encrypted at rest using `cryptography.fernet`
  - Keys stored in secure environment variables
  - Implement key rotation strategy
- **Rate Limiting & Cost Control:**
  - Respect all configured budgets and rate limits
  - Implement circuit breaker for API failures
  - Track and alert on cost overruns
  - Use exponential backoff with jitter for retries
- **Data Protection:**
  - Never log full article content or API keys
  - Mask sensitive data in all log outputs
  - Validate all inputs before API calls
  - Implement request timeouts to prevent DoS

## Acceptance Criteria

1. For 5 sample articles, summaries are generated and stored with model metadata
2. Rate-limit/retry behavior works; failures logged but batch proceeds; concurrency bounded
3. Re-running does not duplicate summaries for the same `(article_id, model)`; provenance fields recorded

## Deliverables

1. `app/summarization/` module (client, prompts, batch CLI)
2. Config entries and documentation
3. Tests with mocked API interactions

## Success Metrics

- ✅ 5 sample articles summarized within token limits
- ✅ Idempotent storage via unique constraint
- ✅ All CI checks pass

## Next Steps

- **Milestone 2.2:** Use summaries in daily top-3 selection and UI
- **Milestone 2.5:** Schedule summarization post-ingestion
